{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "#import sys\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from math import ceil\n",
    "import util\n",
    "from threading import Thread\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.under_sampling import OneSidedSelection\n",
    "from imblearn.under_sampling import NearMiss\n",
    "#-------------------------------\n",
    "# from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "# from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually chosen images that seem to be difficult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['n_of_keypoints', 'avg_perc_brightness', 'contrast', 'edge_length1', 'hue1']\n",
    "man_diff = [\n",
    "'ILSVRC2012_val_00000001.JPEG'\n",
    "'ILSVRC2012_val_00000002.JPEG',\n",
    "'ILSVRC2012_val_00000011.JPEG',\n",
    "'ILSVRC2012_val_00000016.JPEG',\n",
    "'ILSVRC2012_val_00000017.JPEG',\n",
    "'ILSVRC2012_val_00000021.JPEG',\n",
    "'ILSVRC2012_val_00000025.JPEG',\n",
    "'ILSVRC2012_val_00000037.JPEG',\n",
    "'ILSVRC2012_val_00000050.JPEG',\n",
    "'ILSVRC2012_val_00000058.JPEG',\n",
    "'ILSVRC2012_val_00000068.JPEG',\n",
    "'ILSVRC2012_val_00000074.JPEG',\n",
    "'ILSVRC2012_val_00000083.JPEG',\n",
    "'ILSVRC2012_val_00000084.JPEG',\n",
    "'ILSVRC2012_val_00000087.JPEG',\n",
    "'ILSVRC2012_val_00000088.JPEG',\n",
    "'ILSVRC2012_val_00000090.JPEG',\n",
    "'ILSVRC2012_val_00000100.JPEG',\n",
    "'ILSVRC2012_val_00000119.JPEG',\n",
    "'ILSVRC2012_val_00000121.JPEG',\n",
    "'ILSVRC2012_val_00000126.JPEG',\n",
    "'ILSVRC2012_val_00000127.JPEG',\n",
    "'ILSVRC2012_val_00000133.JPEG',\n",
    "'ILSVRC2012_val_00000136.JPEG',\n",
    "'ILSVRC2012_val_00000146.JPEG',\n",
    "'ILSVRC2012_val_00000150.JPEG',\n",
    "'ILSVRC2012_val_00000151.JPEG',\n",
    "'ILSVRC2012_val_00000156.JPEG',\n",
    "'ILSVRC2012_val_00000159.JPEG',\n",
    "'ILSVRC2012_val_00000160.JPEG',\n",
    "'ILSVRC2012_val_00000167.JPEG',\n",
    "'ILSVRC2012_val_00000182.JPEG',\n",
    "'ILSVRC2012_val_00000185.JPEG',\n",
    "'ILSVRC2012_val_00000195.JPEG',\n",
    "'ILSVRC2012_val_00000199.JPEG',\n",
    "'ILSVRC2012_val_00000200.JPEG',\n",
    "'ILSVRC2012_val_00000206.JPEG',\n",
    "'ILSVRC2012_val_00000218.JPEG',\n",
    "'ILSVRC2012_val_00000225.JPEG',\n",
    "'ILSVRC2012_val_00000231.JPEG',\n",
    "'ILSVRC2012_val_00000500.JPEG',\n",
    "'ILSVRC2012_val_00000520.JPEG',\n",
    "'ILSVRC2012_val_00000740.JPEG',\n",
    "'ILSVRC2012_val_00000746.JPEG',\n",
    "'ILSVRC2012_val_00000801.JPEG',\n",
    "'ILSVRC2012_val_00000804.JPEG',\n",
    "'ILSVRC2012_val_00000808.JPEG',\n",
    "'ILSVRC2012_val_00000827.JPEG',\n",
    "'ILSVRC2012_val_00000843.JPEG',\n",
    "'ILSVRC2012_val_00000848.JPEG',\n",
    "'ILSVRC2012_val_00000870.JPEG',\n",
    "'ILSVRC2012_val_00000881.JPEG',\n",
    "'ILSVRC2012_val_00000887.JPEG',\n",
    "'ILSVRC2012_val_00000896.JPEG',\n",
    "'ILSVRC2012_val_00000899.JPEG',\n",
    "'ILSVRC2012_val_00000901.JPEG',\n",
    "'ILSVRC2012_val_00000902.JPEG',\n",
    "'ILSVRC2012_val_00000910.JPEG',\n",
    "'ILSVRC2012_val_00000915.JPEG',\n",
    "'ILSVRC2012_val_00000918.JPEG',\n",
    "'ILSVRC2012_val_00000921.JPEG',\n",
    "]\n",
    "nums =[]\n",
    "for x in man_diff:\n",
    "    nums.append(int(x[15:23]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "first_level = []\n",
    "second_level = []\n",
    "third_level = []\n",
    "row_count = 0\n",
    "with open('all_new_features_hier_norm_top_1.csv', 'rb') as csvfile:\n",
    "    lines = [line.decode('utf-8-sig') for line in csvfile]\n",
    "\n",
    "    for row in csv.reader(lines):\n",
    "        # Remove the headers of csv file\n",
    "        if row_count is 0:\n",
    "            row_count = row_count + 1\n",
    "            continue\n",
    "        if row_count in nums:\n",
    "            temp = row[4:7]\n",
    "            temp.append(row[9])\n",
    "            temp.append(row[10])\n",
    "            data.append(temp)                   # changes what features will be used in the premodel. Here we use every feature except the aspect ratio, and area by perimeter\n",
    "            first_level.append((row[0],row[1]))     # performance of the first level machine\n",
    "            second_level.append((row[0],row[2]))    # performance of the second level machine\n",
    "            third_level.append((row[0],row[3]))     # performance of the third level machine\n",
    "        row_count = row_count + 1\n",
    "        if row_count > 1000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(arg, regr_16):\n",
    "    text_representation = tree.export_text(regr_16, feature_names=feature_list)\n",
    "    print('=========={} CHUNK REPRESENTATION=========='.format(arg))\n",
    "    print(text_representation)\n",
    "#     fig = plt.figure(figsize=(100,80))\n",
    "#     _ = tree.plot_tree(regr_16, feature_names=feature_list, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_fold_worker(test_idx, train_idx, img_data, first_level, second_level, third_level, first_level_machine, second_level_machine, third_level_machine, return_wrapper):\n",
    "    \"\"\"\n",
    "    Worker function for each fold in CV. Trains a model with training data, tests with\n",
    "    test_idx. Places the results as (image, prediction) tuples in return wrapper\n",
    "    Args:\n",
    "        test_idx: List if indexes where the test_data is\n",
    "        train_idx: List if indexes where the train_data is\n",
    "        img_data: all of the image data\n",
    "        first_level: The names of the classes, respective to model return\n",
    "        return_wrapper: The list to add all results\n",
    "    \"\"\"\n",
    "    # Create a validation set which is 10% of the training_data\n",
    "    X_train, _ = util.list_split(img_data, train_idx, [0])\n",
    "    X_train_first_level = X_train\n",
    "    X_train_second_level = X_train\n",
    "    X_train_third_level = X_train\n",
    "\n",
    "\n",
    "    Y_train, _ = util.list_split(img_data, test_idx, [0])\n",
    "    Y_test_first_level, _ = util.list_split(first_level, test_idx, [0])\n",
    "    Y_test_second_level, _ = util.list_split(second_level, test_idx, [0])\n",
    "    Y_test_third_level, _ = util.list_split(third_level, test_idx, [0])\n",
    "\n",
    "    X_test_first_level, _ = util.list_split(first_level, train_idx, [0])\n",
    "    X_test_second_level, _ = util.list_split(second_level, train_idx, [0])\n",
    "    X_test_third_level, _ = util.list_split(third_level, train_idx, [0])\n",
    "\n",
    "    X_val_first_level = [X_test_first_level[i][1] for i in range(0,len(X_test_first_level))]\n",
    "    Y_val_first_level = [Y_test_first_level[i][1] for i in range(0,len(Y_test_first_level))]\n",
    "\n",
    "    X_val_second_level = [X_test_second_level[i][1] for i in range(0,len(X_test_second_level))]\n",
    "    Y_val_second_level = [Y_test_second_level[i][1] for i in range(0,len(Y_test_second_level))]\n",
    "\n",
    "    X_val_third_level = [X_test_third_level[i][1] for i in range(0,len(X_test_third_level))]\n",
    "    Y_val_third_level = [Y_test_third_level[i][1] for i in range(0,len(Y_test_third_level))]\n",
    "\n",
    "    list_predictions = []\n",
    "    Y_train_second_level = []\n",
    "    Y_train_second_level_position = []\n",
    "    Y_train_third_level = []\n",
    "    Y_train_third_level_position = []\n",
    "\n",
    "    ##################################################################################################################\n",
    "    # First Level of hierarchy [Mobilnet_v1]\n",
    "    ##################################################################################################################\n",
    "    if first_level_machine == 'dt16':\n",
    "        predicted_level_2, predicted_level_5, predicted_level_8, predicted_level_12, predicted_level_16 = decision_tree('First Level', X_train_first_level, X_val_first_level, Y_train)\n",
    "        predicted = predicted_level_16\n",
    "    for position, prediction in enumerate(predicted):\n",
    "        if first_level_machine == 'dt16':\n",
    "            if prediction > 0.5:\n",
    "                if Y_test_first_level[position][1] == 1:\n",
    "                    list_predictions.append((Y_test_first_level[position][0], 1, prediction, 1, 'tf-mobilenet_v1'))\n",
    "                else:\n",
    "                    list_predictions.append((Y_test_first_level[position][0], 0, prediction, 1, 'tf-mobilenet_v1'))\n",
    "            else:\n",
    "                Y_train_second_level.append(Y_train[position])\n",
    "                Y_train_second_level_position.append(position)\n",
    "        else:\n",
    "            if prediction == 1:\n",
    "                if Y_test_first_level[position][1] == 1:\n",
    "                    list_predictions.append((Y_test_first_level[position][0], 1, prediction, 1, 'tf-mobilenet_v1'))\n",
    "                else:\n",
    "                    list_predictions.append((Y_test_first_level[position][0], 0, prediction, 1, 'tf-mobilenet_v1'))\n",
    "            else:\n",
    "                Y_train_second_level.append(Y_train[position])\n",
    "                Y_train_second_level_position.append(position)\n",
    "\n",
    "    # Not necessary to go to the next level\n",
    "    if len(Y_train_second_level) == 0:\n",
    "        return_wrapper.append(list_predictions)\n",
    "        return\n",
    "\n",
    "    ##################################################################################################################\n",
    "    # Second Level of hierarchy [Inception_v4]\n",
    "    ##################################################################################################################\n",
    "    if second_level_machine == 'dt16':\n",
    "        predicted_level_2, predicted_level_5, predicted_level_8, predicted_level_12, predicted_level_16 = decision_tree('Second Level', X_train_second_level, X_val_second_level, Y_train_second_level)\n",
    "        predicted = predicted_level_16\n",
    "\n",
    "    for position, prediction in enumerate(predicted):\n",
    "        if second_level_machine == 'dt16':\n",
    "            if prediction > 0.5:\n",
    "                if Y_test_second_level[position][1] == 1:\n",
    "                    list_predictions.append((Y_test_first_level[Y_train_second_level_position[position]][0], 2, prediction, 2, 'tf-inception_v4'))\n",
    "                else:\n",
    "                    list_predictions.append((Y_test_first_level[Y_train_second_level_position[position]][0], 0, prediction, 2, 'tf-inception_v4'))\n",
    "            else:\n",
    "                Y_train_third_level.append(Y_train_second_level[position])\n",
    "                Y_train_third_level_position.append(Y_train_second_level_position[position])\n",
    "        else:\n",
    "            if prediction == 1:\n",
    "                if Y_test_second_level[position][1] == 1:\n",
    "                    list_predictions.append((Y_test_first_level[Y_train_second_level_position[position]][0], 2, prediction, 2, 'tf-inception_v4'))\n",
    "                else:\n",
    "                    list_predictions.append((Y_test_first_level[Y_train_second_level_position[position]][0], 0, prediction, 2, 'tf-inception_v4'))\n",
    "            else:\n",
    "                Y_train_third_level.append(Y_train_second_level[position])\n",
    "                Y_train_third_level_position.append(Y_train_second_level_position[position])\n",
    "\n",
    "    if len(Y_train_third_level) == 0:\n",
    "        return_wrapper.append(list_predictions)\n",
    "        return\n",
    "\n",
    "    ##################################################################################################################\n",
    "    # Third Level of hierarchy [Resnet_v1_152]\n",
    "    ##################################################################################################################\n",
    "    if third_level_machine == 'dt16':\n",
    "        predicted_level_2, predicted_level_5, predicted_level_8, predicted_level_12, predicted_level_16 = decision_tree('Third Level', X_train_third_level, X_val_third_level, Y_train_third_level)\n",
    "        predicted = predicted_level_16\n",
    "\n",
    "    for position, prediction in enumerate(predicted):\n",
    "        if third_level_machine == 'dt16':\n",
    "            if prediction > 0.5:\n",
    "                if Y_test_third_level[position][1] == 1:\n",
    "                    list_predictions.append((Y_test_first_level[Y_train_third_level_position[position]][0], 3, prediction, 3, 'tf-resnet_v1_152'))\n",
    "                else:\n",
    "                    list_predictions.append((Y_test_first_level[Y_train_third_level_position[position]][0], 0, prediction, 3, 'tf-resnet_v1_152'))\n",
    "            else:\n",
    "                if Y_test_third_level[position][1] == 1:\n",
    "                    list_predictions.append((Y_test_first_level[Y_train_third_level_position[position]][0], 3, prediction, 0, 'failed'))\n",
    "                else:\n",
    "                    list_predictions.append((Y_test_first_level[Y_train_third_level_position[position]][0], 0, prediction, 0, 'failed'))\n",
    "        else:\n",
    "            if prediction == 1:\n",
    "                if Y_test_third_level[position][1] == 1:\n",
    "                    list_predictions.append((Y_test_first_level[Y_train_third_level_position[position]][0], 3, prediction, 3, 'tf-resnet_v1_152'))\n",
    "                else:\n",
    "                    list_predictions.append((Y_test_first_level[Y_train_third_level_position[position]][0], 0, prediction, 3, 'tf-resnet_v1_152'))\n",
    "            else:\n",
    "                if Y_test_third_level[position][1] == 1:\n",
    "                    list_predictions.append((Y_test_first_level[Y_train_third_level_position[position]][0], 3, prediction, 0, 'failed'))\n",
    "                else:\n",
    "                    list_predictions.append((Y_test_first_level[Y_train_third_level_position[position]][0], 0, prediction, 0, 'failed'))\n",
    "\n",
    "\n",
    "    return_wrapper.append(list_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prototype(amount_images, list_premodels):\n",
    "    \"\"\"\n",
    "    Produce a .csv file with the fields <Image_filename, Ground truth model, predicted model>\n",
    "    for every image in the train information set. We use k-fold cross validation, where k=10.\n",
    "    \"\"\"\n",
    "    percentage_results = []\n",
    "    report_results = []\n",
    "\n",
    "    if len(list_premodels) == 0:\n",
    "        print(\"No premodels were selected!\")\n",
    "        return percentage_results\n",
    "    if amount_images == 0:\n",
    "        print(\"No images were selected!\")\n",
    "        return percentage_results\n",
    "\n",
    "    #print(\"Creating training data...\")\n",
    "    #data, first_level_data, second_level_data, third_level_data = self.cv_training_data(amount_images)\n",
    "\n",
    "    for counter,(first_level_machine, second_level_machine, third_level_machine) in enumerate(list_premodels):\n",
    "        # Split training data in k-fold chunks\n",
    "        # Minimum needs to be 2\n",
    "        k_fold = 10\n",
    "        worker_threads = list()\n",
    "        chunk_size = int(ceil(len(data) / float(k_fold)))\n",
    "        # Create a new thread for each fold\n",
    "        for i, (test_idx, train_idx) in enumerate(util.chunkise(range(len(data)), chunk_size)):\n",
    "#             print(\"Test_idx: {}, train_idx: {}\".format(test_idx, train_idx))\n",
    "            return_wrapper = list()\n",
    "            p = Thread(target=CV_fold_worker, args=(test_idx, train_idx, data, first_level, second_level, third_level, first_level_machine, second_level_machine, third_level_machine, return_wrapper))\n",
    "            p.start()\n",
    "            worker_threads.append((p, return_wrapper))\n",
    "\n",
    "\n",
    "        # Wait for threads to finish, collect results\n",
    "        all_predictions = list()\n",
    "        for p, ret_val in worker_threads:\n",
    "            p.join()\n",
    "            all_predictions += ret_val\n",
    "\n",
    "        predicted = []\n",
    "        correct_result = []\n",
    "\n",
    "        for p in all_predictions:\n",
    "            for image, groundtruth_label, result_prediction, prediction, model_predicted in p:\n",
    "                correct_result.append(groundtruth_label)\n",
    "                predicted.append(prediction)\n",
    "\n",
    "        percentage_results.append(accuracy_score(predicted, correct_result, [list_premodels[counter]]))\n",
    "        report_results.append(precision_recall_fscore_support(correct_result, predicted, labels = [0, 1]))\n",
    "    return_wrapper = list()\n",
    "    preds = list()\n",
    "    for counter,(first_level_machine, second_level_machine, third_level_machine) in enumerate(list_premodels):\n",
    "        preds.append(CV_fold_worker(test_idx, train_idx, data, first_level, second_level, third_level, first_level_machine, second_level_machine, third_level_machine, return_wrapper))\n",
    "    return percentage_results, report_results, predicted, correct_result, return_wrapper, worker_threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(arg, X_train, X_test, Y_train):\n",
    "    \"\"\"\n",
    "    Decision Tree function that returns the prediction of a list of images. This function allows different deepth levels: 2,5,8,12 and 16\n",
    "    Args:\n",
    "        X_train: List of images features used for training\n",
    "        X_test: List of images results used for validate the trained images.\n",
    "        Y_train: List of images features predicted\n",
    "    \"\"\"\n",
    "\n",
    "    # Create tree\n",
    "    regr_2 = DecisionTreeRegressor(max_depth=2)\n",
    "    regr_5 = DecisionTreeRegressor(max_depth=5)\n",
    "    regr_8 = DecisionTreeRegressor(max_depth=8)\n",
    "    regr_12 = DecisionTreeRegressor(max_depth=12)\n",
    "    regr_16 = DecisionTreeRegressor(max_depth=16)\n",
    "\n",
    "    # Fit tree\n",
    "    regr_2.fit(X_train, X_test)\n",
    "    regr_5.fit(X_train, X_test)\n",
    "    regr_8.fit(X_train, X_test)\n",
    "    regr_12.fit(X_train, X_test)\n",
    "    regr_16.fit(X_train, X_test)\n",
    "\n",
    "    # Predict\n",
    "    predicted_level_2 = regr_2.predict(Y_train)\n",
    "    predicted_level_5 = regr_5.predict(Y_train)\n",
    "    predicted_level_8 = regr_8.predict(Y_train)\n",
    "    predicted_level_12 = regr_12.predict(Y_train)\n",
    "    predicted_level_16 = regr_16.predict(Y_train)\n",
    "    visualize(arg, regr_16)\n",
    "\n",
    "    return predicted_level_2, predicted_level_5, predicted_level_8, predicted_level_12, predicted_level_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========First Level CHUNK REPRESENTATION==========\n",
      "|--- contrast <= -0.36\n",
      "|   |--- contrast <= -0.53\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- contrast >  -0.53\n",
      "|   |   |--- contrast <= -0.45\n",
      "|   |   |   |--- value: [1.00]\n",
      "|   |   |--- contrast >  -0.45\n",
      "|   |   |   |--- contrast <= -0.42\n",
      "|   |   |   |   |--- n_of_keypoints <= 0.18\n",
      "|   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |--- n_of_keypoints >  0.18\n",
      "|   |   |   |   |   |--- contrast <= -0.44\n",
      "|   |   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |   |--- contrast >  -0.44\n",
      "|   |   |   |   |   |   |--- avg_perc_brightness <= -0.41\n",
      "|   |   |   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |   |   |--- avg_perc_brightness >  -0.41\n",
      "|   |   |   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- contrast >  -0.42\n",
      "|   |   |   |   |--- value: [1.00]\n",
      "|--- contrast >  -0.36\n",
      "|   |--- edge_length1 <= 0.47\n",
      "|   |   |--- edge_length1 <= -0.18\n",
      "|   |   |   |--- hue1 <= -0.35\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- hue1 >  -0.35\n",
      "|   |   |   |   |--- n_of_keypoints <= 0.17\n",
      "|   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |--- n_of_keypoints >  0.17\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |--- edge_length1 >  -0.18\n",
      "|   |   |   |--- contrast <= 0.39\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- contrast >  0.39\n",
      "|   |   |   |   |--- n_of_keypoints <= -0.49\n",
      "|   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |--- n_of_keypoints >  -0.49\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |--- edge_length1 >  0.47\n",
      "|   |   |--- edge_length1 <= 1.58\n",
      "|   |   |   |--- value: [1.00]\n",
      "|   |   |--- edge_length1 >  1.58\n",
      "|   |   |   |--- avg_perc_brightness <= 1.71\n",
      "|   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |--- avg_perc_brightness >  1.71\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "\n",
      "==========First Level CHUNK REPRESENTATION==========\n",
      "|--- contrast <= -0.36\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- edge_length1 >  0.42\n",
      "|   |   |   |   |--- n_of_keypoints <= -3.04\n",
      "|   |--- n_of_keypoints <= 0.18\n",
      "|   |   |--- n_of_keypoints <= 0.18\n",
      "|   |   |   |--- contrast <= -0.53\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- contrast >  -0.53\n",
      "|   |   |   |   |--- contrast <= -0.45\n",
      "|   |   |   |   |   |--- hue1 <= 0.75\n",
      "|   |   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |   |--- hue1 >  0.75\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |--- contrast >  -0.45\n",
      "|   |   |   |   |   |--- n_of_keypoints <= 0.18\n",
      "|   |   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |--- n_of_keypoints >  -3.04\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "\n",
      "==========First Level CHUNK REPRESENTATION==========\n",
      "|--- contrast <= -0.36\n",
      "|   |--- edge_length1 <= -0.24\n",
      "|   |   |--- contrast <= 10.46\n",
      "|   |   |   |--- n_of_keypoints <= 0.13\n",
      "|   |   |--- hue1 <= -0.13\n",
      "|   |   |   |--- value: [1.00]\n",
      "|   |   |--- hue1 >  -0.13\n",
      "|   |   |   |   |--- n_of_keypoints <= -3.04\n",
      "|   |   |   |   |   |--- hue1 <= 0.75\n",
      "|   |   |   |--- value: [0.00]\n",
      "|   |--- edge_length1 >  -0.24\n",
      "|   |   |--- hue1 <= -0.37\n",
      "|   |   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |   |--- hue1 >  0.75\n",
      "|   |   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |--- n_of_keypoints >  -3.04\n",
      "|   |   |   |--- value: [0.00]\n",
      "|   |   |--- hue1 >  -0.37\n",
      "|   |   |   |--- value: [1.00]\n",
      "|--- contrast >  -0.36\n",
      "|   |--- contrast <= 0.30\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |--- n_of_keypoints >  0.13\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |--- contrast >  10.46\n",
      "|   |   |--- edge_length1 <= -0.18\n",
      "|   |   |   |--- hue1 <= -0.35\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- hue1 >  -0.35\n",
      "|   |   |   |   |--- avg_perc_brightness <= -0.20\n",
      "|   |   |   |--- value: [0.00]\n",
      "\n",
      "==========First Level CHUNK REPRESENTATION==========\n",
      "|--- contrast <= -0.36\n",
      "|   |   |   |--- value: [0.00]\n",
      "\n",
      "==========Second Level CHUNK REPRESENTATION==========\n",
      "|--- contrast <= -0.36\n",
      "|   |   |   |--- value: [0.00]\n",
      "|   |--- value: [1.00]\n",
      "|--- hue1 >  -0.41\n",
      "|   |--- hue1 <= -0.23\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- hue1 >  -0.23\n",
      "|   |--- contrast <= -0.45\n",
      "|   |   |--- value: [1.00]\n",
      "|   |--- contrast >  -0.45\n",
      "|   |   |--- n_of_keypoints <= 0.18\n",
      "|   |   |   |--- value: [0.00]\n",
      "|   |   |--- n_of_keypoints >  0.18\n",
      "|   |   |--- edge_length1 <= -0.24\n",
      "|   |   |   |--- avg_perc_brightness <= -0.07\n",
      "|   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |--- avg_perc_brightness >  -0.07\n",
      "|   |   |   |--- edge_length1 <= -0.30\n",
      "|   |   |   |   |--- edge_length1 <= -0.31\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |--- edge_length1 >  -0.24\n",
      "|   |   |   |--- contrast <= -0.36\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |--- edge_length1 >  -0.31\n",
      "|   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- edge_length1 >  -0.30\n",
      "|   |   |   |   |--- value: [1.00]\n",
      "|--- contrast >  -0.36\n",
      "|   |   |   |   |--- avg_perc_brightness <= -0.29\n",
      "|   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |--- avg_perc_brightness >  -0.29\n",
      "|   |--- contrast <= 0.30\n",
      "|   |   |--- avg_perc_brightness <= -0.30\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |--- contrast >  -0.36\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "\n",
      "==========First Level CHUNK REPRESENTATION==========\n",
      "|--- contrast <= -0.36\n",
      "|   |   |   |   |--- contrast <= -0.45\n",
      "|   |   |   |--- value: [1.00]\n",
      "|   |   |--- avg_perc_brightness >  1.71\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |--- contrast >  -0.45\n",
      "|   |   |   |   |   |--- contrast <= -0.41\n",
      "|   |   |   |   |   |   |--- n_of_keypoints <= 0.18\n",
      "|   |   |   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |   |   |--- n_of_keypoints >  0.18\n",
      "|   |   |   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |   |--- contrast >  -0.41\n",
      "|   |--- n_of_keypoints <= 0.18\n",
      "|   |   |--- n_of_keypoints <= 0.18\n",
      "|   |   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |--- n_of_keypoints >  0.18\n",
      "|   |   |   |--- value: [0.00]\n",
      "|   |--- n_of_keypoints >  0.18\n",
      "|   |   |--- value: [1.00]\n",
      "|--- contrast >  -0.36\n",
      "|   |   |   |--- avg_perc_brightness <= 3.66\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- avg_perc_brightness >  3.66\n",
      "|   |   |   |   |--- contrast <= 10.46\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |--- contrast >  10.46\n",
      "|   |   |   |   |   |--- value: [0.00]\n",
      "\n",
      "==========First Level CHUNK REPRESENTATION==========\n",
      "|--- contrast <= -0.36\n",
      "|   |   |   |   |--- contrast <= -0.45\n",
      "|   |   |   |--- value: [1.00]\n",
      "|   |   |--- avg_perc_brightness >  1.71\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |--- contrast >  -0.45\n",
      "|   |   |   |   |   |--- contrast <= -0.41\n",
      "|   |   |   |   |   |   |--- n_of_keypoints <= 0.18\n",
      "|   |   |   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |   |   |--- n_of_keypoints >  0.18\n",
      "|   |   |   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |   |--- contrast >  -0.41\n",
      "|   |--- n_of_keypoints <= 0.18\n",
      "|   |   |--- n_of_keypoints <= 0.18\n",
      "|   |   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |--- n_of_keypoints >  0.18\n",
      "|   |   |   |--- value: [0.00]\n",
      "|   |--- n_of_keypoints >  0.18\n",
      "|   |   |--- value: [1.00]\n",
      "|--- contrast >  -0.36\n",
      "|   |   |   |--- avg_perc_brightness <= 3.66\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- avg_perc_brightness >  3.66\n",
      "|   |   |   |   |--- contrast <= 10.46\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |--- contrast >  10.46\n",
      "|   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- contrast <= -0.52\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- contrast >  -0.52\n",
      "|   |   |   |   |--- n_of_keypoints <= 0.18\n",
      "|   |   |   |   |   |--- n_of_keypoints <= 0.17\n",
      "|   |   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |   |--- n_of_keypoints >  0.17\n",
      "|   |   |   |   |   |   |--- avg_perc_brightness <= -0.45\n",
      "|   |   |   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |   |   |--- avg_perc_brightness >  -0.45\n",
      "|   |   |   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |--- n_of_keypoints >  0.18\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |--- n_of_keypoints >  0.18\n",
      "|   |   |   |--- value: [0.00]\n",
      "|   |--- n_of_keypoints >  0.18\n",
      "|   |   |--- value: [1.00]\n",
      "|--- contrast >  -0.36\n",
      "|   |--- contrast <= 4.31\n",
      "|   |   |--- edge_length1 <= -0.18\n",
      "|   |   |   |--- hue1 <= -0.35\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- hue1 >  -0.35\n",
      "|   |   |   |   |--- n_of_keypoints <= 0.17\n",
      "|   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |--- n_of_keypoints >  0.17\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |--- edge_length1 >  -0.18\n",
      "|   |   |   |--- hue1 <= -0.39\n",
      "|   |   |   |   |--- contrast <= 0.26\n",
      "|   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |--- contrast >  0.26\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |--- hue1 >  -0.39\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |--- contrast >  4.31\n",
      "|   |   |--- hue1 <= 6.64\n",
      "|   |   |   |--- value: [1.00]\n",
      "|   |   |--- hue1 >  6.64\n",
      "|   |   |   |--- value: [0.00]\n",
      "\n",
      "==========First Level CHUNK REPRESENTATION==========\n",
      "|--- contrast <= -0.36\n",
      "|   |--- edge_length1 <= -0.24\n",
      "|   |   |--- contrast <= -0.44\n",
      "|   |   |   |--- value: [1.00]\n",
      "|   |   |--- contrast >  -0.44\n",
      "|   |   |   |--- avg_perc_brightness <= -0.41\n",
      "|   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |--- avg_perc_brightness >  -0.41\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |--- edge_length1 >  -0.24\n",
      "|   |   |--- hue1 <= -0.37\n",
      "|   |   |   |--- value: [0.00]\n",
      "|   |   |--- hue1 >  -0.37\n",
      "|   |   |   |--- value: [0.00]\n",
      "|   |   |--- n_of_keypoints >  0.17\n",
      "|   |   |   |--- hue1 <= -0.35\n",
      "|   |   |--- contrast <= -0.56\n",
      "|   |   |   |--- value: [1.00]\n",
      "|   |   |--- contrast >  -0.56\n",
      "|   |   |   |--- value: [0.00]\n",
      "|   |--- contrast >  -0.53\n",
      "|   |   |   |--- value: [1.00]\n",
      "|--- contrast >  -0.36\n",
      "|   |--- contrast <= 0.30\n",
      "|   |   |--- edge_length1 <= -0.30\n",
      "|   |   |   |--- value: [1.00]\n",
      "|   |   |--- edge_length1 >  -0.30\n",
      "|   |   |--- value: [1.00]\n",
      "|--- contrast >  -0.45\n",
      "|   |--- avg_perc_brightness <= -0.41\n",
      "|   |   |--- edge_length1 <= -0.28\n",
      "|   |   |   |--- value: [0.00]\n",
      "|   |   |--- edge_length1 >  -0.28\n",
      "|   |   |   |--- edge_length1 <= -0.03\n",
      "|   |   |   |--- value: [0.00]\n",
      "|   |--- contrast >  0.30\n",
      "|   |   |--- hue1 <= -0.27\n",
      "|   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |--- edge_length1 >  -0.03\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- hue1 >  -0.35\n",
      "|   |   |   |   |--- value: [1.00]\n",
      "|   |--- contrast >  0.23\n",
      "|   |   |--- contrast <= 10.46\n",
      "|   |   |   |--- n_of_keypoints <= 0.13\n",
      "|   |   |   |   |--- edge_length1 <= 0.42\n",
      "|   |   |   |   |   |--- avg_perc_brightness <= 1.75\n",
      "|   |   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |   |--- avg_perc_brightness >  1.75\n",
      "|   |   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |--- edge_length1 >  0.42\n",
      "|   |   |   |--- value: [1.00]\n",
      "|   |   |--- hue1 >  -0.27\n",
      "|   |   |   |--- edge_length1 <= 1.58\n",
      "|   |   |   |   |--- contrast <= 3.47\n",
      "|   |   |   |   |   |--- edge_length1 <= 0.23\n",
      "|   |   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |   |--- edge_length1 >  0.23\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |--- n_of_keypoints >  0.13\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |--- contrast >  10.46\n",
      "|   |   |   |--- value: [0.00]\n",
      "\n",
      "==========First Level CHUNK REPRESENTATION==========\n",
      "|--- contrast <= -0.36\n",
      "|   |--- contrast <= -0.53\n",
      "|   |   |--- hue1 <= -0.38\n",
      "|   |   |   |--- value: [1.00]\n",
      "|   |   |--- hue1 >  -0.38\n",
      "|   |   |   |--- value: [0.00]\n",
      "|   |--- contrast >  -0.53\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "\n",
      "==========First Level CHUNK REPRESENTATION==========\n",
      "|--- contrast <= -0.36\n",
      "|   |--- contrast <= -0.53\n",
      "|   |   |--- hue1 <= -0.38\n",
      "|   |   |   |--- value: [1.00]\n",
      "|   |   |--- hue1 >  -0.38\n",
      "|   |   |   |--- value: [0.00]\n",
      "|   |--- contrast >  -0.53\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |--- contrast <= -0.44\n",
      "|   |   |   |--- value: [1.00]\n",
      "|   |   |--- contrast >  -0.44\n",
      "|   |   |   |--- contrast <= -0.42\n",
      "|   |   |   |   |--- edge_length1 <= -0.28\n",
      "|   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |--- edge_length1 >  -0.28\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |--- contrast >  -0.42\n",
      "|   |   |   |   |--- value: [1.00]\n",
      "|--- contrast >  -0.36\n",
      "|   |--- edge_length1 <= -0.23\n",
      "|   |   |--- hue1 <= -0.35\n",
      "|   |   |   |--- value: [0.00]\n",
      "|   |   |--- hue1 >  -0.35\n",
      "|   |   |   |--- value: [1.00]\n",
      "|   |--- edge_length1 >  -0.23\n",
      "|   |   |--- contrast <= 0.30\n",
      "|   |   |   |--- avg_perc_brightness <= -0.30\n",
      "|   |   |   |   |--- contrast <= -0.14\n",
      "|   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |--- contrast >  -0.14\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |--- avg_perc_brightness >  -0.30\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |--- contrast >  0.30\n",
      "|   |   |   |--- hue1 <= -0.27\n",
      "|   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |--- hue1 >  -0.27\n",
      "|   |   |   |   |--- avg_perc_brightness <= 6.69\n",
      "|   |   |   |   |   |--- edge_length1 <= 0.23\n",
      "|   |   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |   |--- edge_length1 >  0.23\n",
      "|   |   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |--- avg_perc_brightness >  6.69\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "\n",
      "==========Second Level CHUNK REPRESENTATION==========\n",
      "|--- hue1 <= -0.41\n",
      "|   |--- edge_length1 <= 0.19\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- edge_length1 >  0.19\n",
      "|   |   |--- value: [1.00]\n",
      "|--- hue1 >  -0.41\n",
      "|   |--- hue1 <= -0.23\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- hue1 >  -0.23\n",
      "|   |   |   |   |   |   |--- avg_perc_brightness <= -0.30\n",
      "|   |   |   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |   |   |--- avg_perc_brightness >  -0.30\n",
      "|   |   |--- n_of_keypoints <= 0.16\n",
      "|   |   |   |--- value: [0.00]\n",
      "|   |   |--- n_of_keypoints >  0.16\n",
      "|   |   |   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |   |--- hue1 >  -0.37\n",
      "|   |   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |--- hue1 >  -0.33\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |--- avg_perc_brightness >  0.27\n",
      "|   |   |   |--- avg_perc_brightness <= 0.68\n",
      "|   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |--- avg_perc_brightness >  0.68\n",
      "|   |   |   |--- avg_perc_brightness <= -0.31\n",
      "|   |   |   |   |--- hue1 <= -0.05\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |--- hue1 >  -0.05\n",
      "|   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- avg_perc_brightness >  -0.31\n",
      "|   |   |   |   |--- value: [1.00]\n",
      "\n",
      "==========Third Level CHUNK REPRESENTATION==========\n",
      "|--- edge_length1 <= -0.30\n",
      "|   |--- contrast <= -0.44\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- contrast >  -0.44\n",
      "|   |   |--- value: [1.00]\n",
      "|--- edge_length1 >  -0.30\n",
      "|   |--- value: [0.00]\n",
      "==========First Level CHUNK REPRESENTATION==========\n",
      "|--- edge_length1 <= -0.30\n",
      "|   |--- contrast <= -0.44\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- contrast >  -0.44\n",
      "|   |   |--- value: [1.00]\n",
      "|--- edge_length1 >  -0.30\n",
      "|   |--- value: [0.00]\n",
      "|   |   |   |   |   |--- avg_perc_brightness <= 5.21\n",
      "|   |   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |   |--- avg_perc_brightness >  5.21\n",
      "|   |   |   |   |   |   |--- value: [0.00]\n",
      "\n",
      "\n",
      "==========Second Level CHUNK REPRESENTATION==========\n",
      "|--- hue1 <= -0.41\n",
      "|   |--- edge_length1 <= 0.19\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- edge_length1 >  0.19\n",
      "|   |   |--- value: [1.00]\n",
      "|--- hue1 >  -0.41\n",
      "|   |--- hue1 <= -0.23\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- hue1 >  -0.23\n",
      "|   |   |--- edge_length1 <= -0.24\n",
      "|   |   |   |--- contrast <= -0.44\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- contrast >  -0.44\n",
      "|   |   |   |   |--- value: [1.00]\n",
      "|   |   |--- edge_length1 >  -0.24\n",
      "|   |   |   |--- contrast <= -0.36\n",
      "|   |   |   |   |--- hue1 <= 0.15\n",
      "|   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |--- hue1 >  0.15\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |--- contrast >  -0.36\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "\n",
      "==========Second Level CHUNK REPRESENTATION====================Second Level CHUNK REPRESENTATION==========\n",
      "|--- hue1 <= -0.41\n",
      "|   |--- avg_perc_brightness <= -0.42\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- avg_perc_brightness >  -0.42\n",
      "|   |   |--- value: [1.00]\n",
      "|--- hue1 >  -0.41\n",
      "|   |--- hue1 <= -0.23\n",
      "|   |   |--- value: [1.00]\n",
      "|   |--- contrast >  0.26\n",
      "|   |   |--- value: [0.00]\n",
      "|--- hue1 >  -0.41\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- hue1 >  -0.23\n",
      "|   |   |--- edge_length1 <= -0.24\n",
      "|   |   |   |--- value: [1.00]\n",
      "|   |   |--- edge_length1 >  -0.24\n",
      "|   |--- hue1 <= -0.23\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- hue1 >  -0.23\n",
      "|   |   |   |--- contrast <= -0.36\n",
      "|   |   |   |   |--- n_of_keypoints <= 0.17\n",
      "|   |   |--- edge_length1 <= -0.24\n",
      "|   |   |   |--- contrast <= -0.44\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |--- n_of_keypoints >  0.17\n",
      "|   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- contrast >  -0.36\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- contrast >  -0.44\n",
      "|   |   |   |   |--- value: [1.00]\n",
      "|   |   |--- edge_length1 >  -0.24\n",
      "|   |   |   |--- contrast <= -0.36\n",
      "|   |   |   |   |--- n_of_keypoints <= 0.17\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |--- n_of_keypoints >  0.17\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "\n",
      "\n",
      "|--- hue1 <= -0.41\n",
      "|   |--- avg_perc_brightness <= -0.42\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- avg_perc_brightness >  -0.42\n",
      "|   |   |--- value: [1.00]\n",
      "|--- hue1 >  -0.41\n",
      "|   |--- hue1 <= -0.23\n",
      "|   |   |--- value: [1.00]\n",
      "|   |--- contrast >  0.26\n",
      "|   |   |--- value: [0.00]\n",
      "|--- hue1 >  -0.41\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- hue1 >  -0.23\n",
      "|   |   |--- edge_length1 <= -0.24\n",
      "|   |   |   |--- value: [1.00]\n",
      "|   |   |--- edge_length1 >  -0.24\n",
      "|   |--- hue1 <= -0.23\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- hue1 >  -0.23\n",
      "|   |   |   |--- contrast <= -0.36\n",
      "|   |   |   |   |--- n_of_keypoints <= 0.17\n",
      "|   |   |--- edge_length1 <= -0.24\n",
      "|   |   |   |--- contrast <= -0.44\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |--- n_of_keypoints >  0.17\n",
      "|   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- contrast >  -0.36\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- contrast >  -0.44\n",
      "|   |   |   |   |--- value: [1.00]\n",
      "|   |   |--- edge_length1 >  -0.24\n",
      "|   |   |   |--- contrast <= -0.36\n",
      "|   |   |   |   |--- n_of_keypoints <= 0.17\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |--- n_of_keypoints >  0.17\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- contrast >  -0.36\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "\n",
      "==========Third Level CHUNK REPRESENTATION==========\n",
      "|--- value: [0.00]\n",
      "\n",
      "==========Second Level CHUNK REPRESENTATION==========\n",
      "|--- hue1 <= -0.41\n",
      "|   |--- contrast <= 0.26\n",
      "|   |   |--- value: [1.00]\n",
      "|   |--- contrast >  0.26\n",
      "|   |   |--- value: [0.00]\n",
      "|--- hue1 >  -0.41\n",
      "|   |--- hue1 <= -0.23\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- hue1 >  -0.23\n",
      "|   |   |--- n_of_keypoints <= 0.16\n",
      "|   |   |   |--- value: [0.00]\n",
      "|   |   |--- n_of_keypoints >  0.16\n",
      "|   |   |   |--- hue1 <= -0.05\n",
      "|   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |--- hue1 >  -0.05\n",
      "|   |   |   |   |--- avg_perc_brightness <= -0.29\n",
      "|   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |--- avg_perc_brightness >  -0.29\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "\n",
      "==========Third Level CHUNK REPRESENTATION====================Second Level CHUNK REPRESENTATION==========\n",
      "\n",
      "|--- edge_length1 <= -0.30\n",
      "|   |   |--- value: [1.00]\n",
      "|   |--- hue1 >  -0.05\n",
      "|   |   |--- contrast <= -0.36\n",
      "|   |   |--- value: [1.00]\n",
      "|--- hue1 >  -0.41\n",
      "|   |--- hue1 <= -0.23\n",
      "|   |--- edge_length1 <= -0.31\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- edge_length1 >  -0.31\n",
      "|   |   |   |--- contrast <= -0.38\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- contrast >  -0.38\n",
      "|   |   |   |   |--- value: [1.00]\n",
      "|   |   |--- contrast >  -0.36\n",
      "|   |   |--- value: [1.00]\n",
      "|--- edge_length1 >  -0.30\n",
      "|   |--- value: [0.00]\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- hue1 >  -0.23\n",
      "|   |   |--- edge_length1 <= -0.24\n",
      "|   |   |   |--- value: [0.00]\n",
      "\n",
      "|--- edge_length1 <= -0.30\n",
      "|   |   |--- value: [1.00]\n",
      "|   |--- hue1 >  -0.05\n",
      "|   |   |--- contrast <= -0.36\n",
      "|   |   |--- value: [1.00]\n",
      "|--- hue1 >  -0.41\n",
      "|   |--- hue1 <= -0.23\n",
      "|   |--- edge_length1 <= -0.31\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- edge_length1 >  -0.31\n",
      "|   |   |   |--- contrast <= -0.38\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- contrast >  -0.38\n",
      "|   |   |   |   |--- value: [1.00]\n",
      "|   |   |--- contrast >  -0.36\n",
      "|   |   |--- value: [1.00]\n",
      "|--- edge_length1 >  -0.30\n",
      "|   |--- value: [0.00]\n",
      "\n",
      "==========Second Level CHUNK REPRESENTATION==========\n",
      "|--- hue1 <= -0.41\n",
      "|   |--- edge_length1 <= 0.19\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |--- contrast >  -0.36\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "\n",
      "==========Second Level CHUNK REPRESENTATION==========\n",
      "|--- hue1 <= -0.41\n",
      "|   |--- edge_length1 <= 0.19\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |--- contrast >  -0.36\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- edge_length1 >  0.19\n",
      "|   |   |--- value: [1.00]\n",
      "|--- hue1 >  -0.41\n",
      "|   |--- avg_perc_brightness <= -0.20\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- avg_perc_brightness >  -0.20\n",
      "|   |   |--- n_of_keypoints <= 0.16\n",
      "|   |   |   |--- value: [0.00]\n",
      "|   |   |--- n_of_keypoints >  0.16\n",
      "|   |   |   |--- value: [1.00]\n",
      "\n",
      "==========Third Level CHUNK REPRESENTATION==========\n",
      "|--- hue1 <= -0.41\n",
      "|   |   |--- value: [1.00]\n",
      "|--- edge_length1 >  -0.30\n",
      "|   |--- value: [0.00]\n",
      "\n",
      "==========Second Level CHUNK REPRESENTATION==========\n",
      "|--- hue1 <= -0.41\n",
      "|   |   |--- value: [1.00]\n",
      "|--- edge_length1 >  -0.30\n",
      "|   |--- value: [0.00]\n",
      "|   |--- avg_perc_brightness <= -0.42\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- avg_perc_brightness >  -0.42\n",
      "|   |   |--- value: [1.00]\n",
      "|--- hue1 >  -0.41\n",
      "|   |--- hue1 <= -0.23\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- hue1 >  -0.23\n",
      "|   |   |--- edge_length1 <= -0.24\n",
      "|   |   |   |--- contrast <= -0.44\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |--- contrast >  -0.44\n",
      "|   |   |   |   |--- value: [1.00]\n",
      "|   |   |--- edge_length1 >  -0.24\n",
      "|   |   |   |--- contrast <= -0.36\n",
      "|   |   |   |   |--- contrast <= -0.38\n",
      "|   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |--- contrast >  -0.38\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |--- contrast >  -0.36\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "\n",
      "==========Third Level CHUNK REPRESENTATION==========\n",
      "|--- edge_length1 <= -0.30\n",
      "|   |--- edge_length1 <= -0.31\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- edge_length1 >  -0.31\n",
      "|   |   |--- value: [1.00]\n",
      "|--- edge_length1 >  -0.30\n",
      "|   |--- value: [0.00]\n",
      "\n",
      "==========Third Level CHUNK REPRESENTATION==========\n",
      "|--- edge_length1 <= -0.30\n",
      "|   |--- contrast <= -0.44\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- contrast >  -0.44\n",
      "|   |   |--- value: [1.00]\n",
      "|--- edge_length1 >  -0.30\n",
      "|   |--- value: [0.00]\n",
      "\n",
      "==========Third Level CHUNK REPRESENTATION====================Third Level CHUNK REPRESENTATION==========\n",
      "|--- edge_length1 <= -0.30\n",
      "|   |--- edge_length1 <= -0.31\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- edge_length1 >  -0.31\n",
      "|   |--- n_of_keypoints <= 0.18\n",
      "|   |   |--- value: [1.00]\n",
      "|   |--- n_of_keypoints >  0.18\n",
      "|   |   |--- value: [0.00]\n",
      "|--- edge_length1 >  -0.30\n",
      "|   |   |--- value: [1.00]\n",
      "|--- edge_length1 >  -0.30\n",
      "|   |--- value: [0.00]\n",
      "\n",
      "\n",
      "|--- edge_length1 <= -0.30\n",
      "|   |--- edge_length1 <= -0.31\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- edge_length1 >  -0.31\n",
      "|   |--- n_of_keypoints <= 0.18\n",
      "|   |   |--- value: [1.00]\n",
      "|   |--- n_of_keypoints >  0.18\n",
      "|   |   |--- value: [0.00]\n",
      "|--- edge_length1 >  -0.30\n",
      "|   |   |--- value: [1.00]\n",
      "|--- edge_length1 >  -0.30\n",
      "|   |--- value: [0.00]\n",
      "|   |--- value: [0.00]\n",
      "\n",
      "==========Third Level CHUNK REPRESENTATION==========\n",
      "|--- edge_length1 <= -0.30\n",
      "|   |--- contrast <= -0.44\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- contrast >  -0.44\n",
      "|   |   |--- value: [1.00]\n",
      "|--- edge_length1 >  -0.30\n",
      "|   |--- value: [0.00]\n",
      "\n",
      "==========Third Level CHUNK REPRESENTATION==========\n",
      "|--- edge_length1 <= -0.30\n",
      "|   |--- contrast <= -0.45\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- contrast >  -0.45\n",
      "|   |   |--- value: [1.00]\n",
      "|--- edge_length1 >  -0.30\n",
      "|   |--- value: [0.00]\n",
      "\n",
      "==========First Level CHUNK REPRESENTATION==========\n",
      "|--- contrast <= -0.36\n",
      "|   |--- edge_length1 <= -0.24\n",
      "|   |   |--- contrast <= -0.44\n",
      "|   |   |   |--- value: [1.00]\n",
      "|   |   |--- contrast >  -0.44\n",
      "|   |   |   |--- avg_perc_brightness <= -0.41\n",
      "|   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |--- avg_perc_brightness >  -0.41\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "|   |--- edge_length1 >  -0.24\n",
      "|   |   |--- hue1 <= -0.37\n",
      "|   |   |   |--- value: [0.00]\n",
      "|   |   |--- hue1 >  -0.37\n",
      "|   |   |   |--- value: [1.00]\n",
      "|--- contrast >  -0.36\n",
      "|   |--- contrast <= 0.30\n",
      "|   |   |--- edge_length1 <= -0.30\n",
      "|   |   |   |--- value: [1.00]\n",
      "|   |   |--- edge_length1 >  -0.30\n",
      "|   |   |   |--- value: [0.00]\n",
      "|   |--- contrast >  0.30\n",
      "|   |   |--- hue1 <= -0.27\n",
      "|   |   |   |--- value: [1.00]\n",
      "|   |   |--- hue1 >  -0.27\n",
      "|   |   |   |--- edge_length1 <= 1.58\n",
      "|   |   |   |   |--- edge_length1 <= 0.42\n",
      "|   |   |   |   |   |--- edge_length1 <= 0.23\n",
      "|   |   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |   |   |--- edge_length1 >  0.23\n",
      "|   |   |   |   |   |   |--- value: [0.00]\n",
      "|   |   |   |   |--- edge_length1 >  0.42\n",
      "|   |   |   |   |   |--- value: [1.00]\n",
      "|   |   |   |--- edge_length1 >  1.58\n",
      "|   |   |   |   |--- value: [0.00]\n",
      "\n",
      "==========Second Level CHUNK REPRESENTATION==========\n",
      "|--- hue1 <= -0.41\n",
      "|   |--- avg_perc_brightness <= -0.42\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- avg_perc_brightness >  -0.42\n",
      "|   |   |--- value: [1.00]\n",
      "|--- hue1 >  -0.41\n",
      "|   |--- avg_perc_brightness <= -0.20\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- avg_perc_brightness >  -0.20\n",
      "|   |   |--- n_of_keypoints <= 0.16\n",
      "|   |   |   |--- value: [0.00]\n",
      "|   |   |--- n_of_keypoints >  0.16\n",
      "|   |   |   |--- value: [1.00]\n",
      "\n",
      "==========Third Level CHUNK REPRESENTATION==========\n",
      "|--- edge_length1 <= -0.30\n",
      "|   |--- contrast <= -0.44\n",
      "|   |   |--- value: [0.00]\n",
      "|   |--- contrast >  -0.44\n",
      "|   |   |--- value: [1.00]\n",
      "|--- edge_length1 >  -0.30\n",
      "|   |--- value: [0.00]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\miniconda3\\envs\\esrg\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass normalize=[('dt16', 'dt16', 'dt16')] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n",
      "C:\\Users\\Asus\\miniconda3\\envs\\esrg\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "output_dt16 = prototype(30, ([('dt16', 'dt16', 'dt16')]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "def img_num_from_name(img_name):          # obtaining the image number from image name\n",
    "    ext = []\n",
    "    for i in range(len(img_name)):\n",
    "        if i > 14 and i < 23:\n",
    "            ext.append(img_name[i])\n",
    "    j = 0\n",
    "    for i in range(len(ext)):\n",
    "        if ext[i] == '0':\n",
    "            j = j + 1\n",
    "        if ext[i] != '0':\n",
    "            break\n",
    "    rightNum = []\n",
    "    for i in range(j, len(ext)):\n",
    "        rightNum.append(ext[i])\n",
    "    rightNum = ''.join(rightNum)\n",
    "    rightNum = int(rightNum)\n",
    "    return rightNum\n",
    "\n",
    "predicted_models_dt16 = []                                    # models predicted by dt16 premodel            \n",
    "for i in range(10):\n",
    "    for j in range(len(output_dt16[5][i][1][0])):\n",
    "        img_paths = (output_dt16[5][i][1][0][j][0])\n",
    "        img_nums = (img_num_from_name(img_paths))\n",
    "        if output_dt16[5][i][1][0][j][4] == 'tf-mobilenet_v1' and output_dt16[5][i][1][0][j][3] == 1:\n",
    "            predicted_models_dt16.append([img_nums, 'mobilenet_v1'])\n",
    "        elif output_dt16[5][i][1][0][j][4] == 'tf-inception_v4' and output_dt16[5][i][1][0][j][3] == 2:\n",
    "            predicted_models_dt16.append([img_nums, 'inception_v4'])\n",
    "        elif output_dt16[5][i][1][0][j][4] == 'tf-resnet_v1_152' and output_dt16[5][i][1][0][j][3] == 3:\n",
    "            predicted_models_dt16.append([img_nums, 'resnet_v1_152'])\n",
    "        elif output_dt16[5][i][1][0][j][4] == 'failed':\n",
    "            predicted_models_dt16.append([img_nums, 'failed'])\n",
    "print(len(predicted_models_dt16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[11, 'mobilenet_v1'],\n",
       " [17, 'mobilenet_v1'],\n",
       " [21, 'mobilenet_v1'],\n",
       " [25, 'mobilenet_v1'],\n",
       " [1, 'inception_v4'],\n",
       " [16, 'failed'],\n",
       " [37, 'mobilenet_v1'],\n",
       " [58, 'mobilenet_v1'],\n",
       " [68, 'mobilenet_v1'],\n",
       " [74, 'mobilenet_v1'],\n",
       " [50, 'failed'],\n",
       " [83, 'failed'],\n",
       " [84, 'mobilenet_v1'],\n",
       " [87, 'mobilenet_v1'],\n",
       " [88, 'mobilenet_v1'],\n",
       " [90, 'mobilenet_v1'],\n",
       " [100, 'mobilenet_v1'],\n",
       " [119, 'failed'],\n",
       " [126, 'mobilenet_v1'],\n",
       " [127, 'mobilenet_v1'],\n",
       " [121, 'failed'],\n",
       " [133, 'failed'],\n",
       " [136, 'failed'],\n",
       " [146, 'failed'],\n",
       " [156, 'mobilenet_v1'],\n",
       " [159, 'mobilenet_v1'],\n",
       " [150, 'failed'],\n",
       " [151, 'failed'],\n",
       " [160, 'failed'],\n",
       " [167, 'failed'],\n",
       " [182, 'mobilenet_v1'],\n",
       " [185, 'mobilenet_v1'],\n",
       " [195, 'mobilenet_v1'],\n",
       " [199, 'failed'],\n",
       " [200, 'resnet_v1_152'],\n",
       " [206, 'failed'],\n",
       " [218, 'mobilenet_v1'],\n",
       " [520, 'mobilenet_v1'],\n",
       " [740, 'mobilenet_v1'],\n",
       " [225, 'failed'],\n",
       " [231, 'failed'],\n",
       " [500, 'failed'],\n",
       " [746, 'mobilenet_v1'],\n",
       " [801, 'mobilenet_v1'],\n",
       " [827, 'mobilenet_v1'],\n",
       " [843, 'mobilenet_v1'],\n",
       " [804, 'failed'],\n",
       " [808, 'failed'],\n",
       " [848, 'mobilenet_v1'],\n",
       " [881, 'mobilenet_v1'],\n",
       " [896, 'mobilenet_v1'],\n",
       " [899, 'mobilenet_v1'],\n",
       " [870, 'failed'],\n",
       " [887, 'failed'],\n",
       " [918, 'mobilenet_v1'],\n",
       " [901, 'failed'],\n",
       " [902, 'failed'],\n",
       " [910, 'failed'],\n",
       " [915, 'failed'],\n",
       " [921, 'failed']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_models_dt16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT16 premodel accuracy = 0.3333333333333333\n",
      "DT16 premodel average inference time = 250.00882000000001\n"
     ]
    }
   ],
   "source": [
    "import database\n",
    "n = 1\n",
    "accuracy_premodel = 0\n",
    "time_premodel = 0\n",
    "times = 0\n",
    "dt16_premodel_overhead = 43.00882                                           # average dt16 premodel overhead\n",
    "\n",
    "for i in range(len(predicted_models_dt16)):\n",
    "    if predicted_models_dt16[i][1] != 'failed':\n",
    "        times = times + 1                           # get_model_top_n (next line), where n is 1 or 5\n",
    "        accuracy_premodel = accuracy_premodel + (database.get_model_top_n(\"inference\", predicted_models_dt16[i][0], predicted_models_dt16[i][1], n))\n",
    "        time_premodel = time_premodel + (database.get_model_time(\"inference\", predicted_models_dt16[i][0], predicted_models_dt16[i][1]))\n",
    "\n",
    "dt16_accuracy = accuracy_premodel/len(predicted_models_dt16)                        # dt16 premodel accuracy\n",
    "dt16_time = (time_premodel/times) + dt16_premodel_overhead                             # dt16 premodel inference time\n",
    "print(\"DT16 premodel accuracy = {}\".format(dt16_accuracy))\n",
    "print(\"DT16 premodel average inference time = {}\".format(dt16_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c2509c9860>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEICAYAAACwDehOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWVklEQVR4nO3de7RedX3n8fcHCAYQzYWTGIkRbVPQMgvEU4apwqgR7zZhXLisl4lIDV6q2HassdbiZVjDzLi8zDhjm1XrBC+MUaBQtWKIgtoqToCgXJtCIURiEkO0gkS5fOePZ5/tMZycPOf2PEnO+7VW1n72b19+37iWfPLbv31JVSFJEsBB/S5AkrTvMBQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhS0X0hy37A/jyR5YNj6ayapj0OTfDHJnUkqyXMm47zS/sRQ0H6hqh479AfYBLx8WNtnJ7GrbwOvBX40ieecEkkO7ncNOvAYCtqvJXlMko8muaf589Ekj2m2PSfJ5iR/luTHzQhgj6OKqvplVX20qr4NPNxF32cluSXJz5LckeSc3bYvTbIhyb8muT3Ji5r2OUk+1dS7M8nfNu2vT/Lt3c5RSX6z+f1/knwiyVeS3A88N8lLk1zf9HF3kvftdvyzk/xjkp8021+f5HeSbE1yyLD9XpFkw97+zjrwGQra370HOAU4ETgBOBn482HbnwAcBRwNLAdWJTl2kvreBrwMeBxwFvCRJCcBJDkZuBB4JzALOA24sznu08DhwG8D84CPjKHPVwPnA0fSGdXcD/zHpo+XAm9OsqypYRHw98D/BAbo/G+0oar+H7ADOH3YeV/b1KVpzlDQ/u41wAeqaltVbQfeD7xut33eW1W/qKqrgS8Dr5yMjqvqy1V1e3VcDXwNOLXZfDbwN1W1tqoeqaofVtWtSRYALwbeVFU7q+rB5thuXVZV/9Ccc1dVXVVVP2jWvw9cBPz7Zt/XAFdW1UVNPzuqakOzbTWdICDJHOCFwOcm8r+HDgyGgvZ3TwTuGrZ+V9M2ZGdV3b/79iSLhk9ej6fjJC9O8t0k9yb5CfASOqMSgCcBt49w2JOAe6tq53j6BO7erYZ/m+QbSbYn+Snwpi5qAPgM8PIkj6UTkt+qqi3jrEkHEENB+7t7gCcPW1/UtA2ZneSI3bdX1abdJq/HpJm3uBj4EDC/qmYBXwHS7HI38BsjHHo3MCfJrBG23U/nstJQH08YYZ/dX2v8OeBy4ElV9XjgL7uogar6IfAd4Aw6IysvHQkwFLT/uwj48yQDSY4C/oLOv4KHe39zu+mpdOYAvrCnkzUT1zOb1UOTzEySEXY9FHgMsB14KMmLgRcM2/5J4KwkS5IclOToJMc1/xr/e+B/J5mdZEaS05pjbgB+O8mJTQ3v6+LvfySdkceuZh7j1cO2fRZ4fpJXJjkkydwkJw7bfiHwp8C/AS7toi9NA4aC9nf/GVgPfB/4AXBd0zbkR8BOOqOHz9K5ln/rKOe7DXiAzsT0Fc3vJ+++U1X9DHg7sKY5/6vp/It9aPv3aCafgZ8CVw87z+uAB4Fb6UxWv6M55p+ADwBXAhvpTCTvzVuADyT5GZ1AXDOshk10Lmn9CXAvsIHOZPyQS5uaLt3tEpumsfiRHR2omofPPlNVC/tcyj4rye3AOVV1Zb9r0b7BkYI0TSV5BZ05iq/3uxbtO6YsFJL8TZJtSW4c1jYnydokG5vl7GHb3p3kn5PcluSFU1WXJEhyFfAJ4K1V9Uify9E+ZMouHzWTZ/cBF1bV8U3bf6MzKXZBkpXA7Kp6V5Kn05kwPJnO7YRXAr9VVXt9qlSSNHmmbKRQVd+kM7k13FI6D83QLJcNa/+/zQNG/wL8M52AkCT10CF732VSzR96QKaqtiSZ17QfDXx32H6bm7ZHSbICWAFwxBFHPPO4446bwnIl6cBz7bXX/riqBkba1utQ2JOR7gMf8bpWVa0CVgEMDg7W+vXrp7IuSTrgJLlrT9t6fffR1ubdLzTLbU37ZjqP5A9ZyK8/lSpJ6oFeh8LldN5USbO8bFj7q5qnSZ8CLAa+1+PaJGnam7LLR0kuAp4DHJVkM3AecAGwJsnZdD6UciZAVd2UZA1wM/AQndvkvPNIknpsykKhqn5/D5uW7GH/8+m8J16S1KUHH3yQzZs3s2vXrkdtmzlzJgsXLmTGjBldn29fmWiWJI3D5s2bOfLIIznmmGMY/u7GqmLHjh1s3ryZpzzlKV2fz9dcSNJ+bNeuXcydO/fXAgEgCXPnzh1xBDEaQ0GS9nMjv919z+2jMRQkSS1DQZLUMhQkaT+3pxebjueFp4aCJO3HZs6cyY4dOx4VAEN3H82cOXMPR47MW1IlaT+2cOFCNm/ezPbt2x+1beg5hbEwFCRpPzZjxowxPYewN14+kiS1DAVJUstQkCS1DAVJUstQkCS1DAVJUstQkCS1DAVJUstQkCS1+hIKSc5NcmOSm5K8o2mbk2Rtko3NcnY/apOk6aznoZDkeOCNwMnACcDLkiwGVgLrqmoxsK5ZlyT1UD9GCk8DvltVP6+qh4CrgTOApcDqZp/VwLI+1CZJ01o/QuFG4LQkc5McDrwEeBIwv6q2ADTLeX2oTZKmtZ6/JbWqbknyX4G1wH3ADcBD3R6fZAWwAmDRokVTUqMkTVd9mWiuqk9W1UlVdRpwL7AR2JpkAUCz3LaHY1dV1WBVDQ4MDPSuaEmaBvp199G8ZrkI+A/ARcDlwPJml+XAZf2oTZKms359ZOfiJHOBB4G3VtXOJBcAa5KcDWwCzuxTbZI0bfUlFKrq1BHadgBL+lCOJKnhE82SpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpFZfQiHJHyW5KcmNSS5KMjPJnCRrk2xslrP7UZskTWc9D4UkRwNvBwar6njgYOBVwEpgXVUtBtY165KkHurX5aNDgMOSHAIcDtwDLAVWN9tXA8v6U5okTV89D4Wq+iHwIWATsAX4aVV9DZhfVVuafbYA80Y6PsmKJOuTrN++fXuvypakaaEfl49m0xkVPAV4InBEktd2e3xVraqqwaoaHBgYmKoyJWla6sflo+cD/1JV26vqQeAS4HeBrUkWADTLbX2oTZKmtX6EwibglCSHJwmwBLgFuBxY3uyzHLisD7VJ0rR2SK87rKprknwRuA54CLgeWAU8FliT5Gw6wXFmr2uTpOmu56EAUFXnAeft1vwLOqMGSVKf+ESzJKllKEiSWoaCJKllKEiSWoaCJKllKEiSWoaCJKllKEiSWoaCJKllKEiSWoaCJKllKEiSWoaCJKllKEiSWoaCJKllKEiSWoaCJKllKEiSWnv9HGeSQeBU4InAA8CNwJVVde94OkxyLPD5YU1PBf4CuLBpPwa4E3hlVe0cTx+SpPHZ40ghyeuTXAe8GzgMuA3YBjwbWJtkdZJFY+2wqm6rqhOr6kTgmcDPgUuBlcC6qloMrGvWJUk9NNpI4QjgWVX1wEgbk5wILAY2TaD/JcDtVXVXkqXAc5r21cBVwLsmcG5J0hjtMRSq6n+NdmBVbZiE/l8FXNT8nl9VW5pzb0kyb6QDkqwAVgAsWjTmgYokaRRdTzQneXmSa5JsSPKWiXac5FDg94AvjOW4qlpVVYNVNTgwMDDRMiRJw4w2p3DCbk2vA04BTgLePAl9vxi4rqq2Nutbkyxo+l5AZ/5CktRDo40U3pJkVZInNOt3A+cDHwDumYS+f59fXToCuBxY3vxeDlw2CX1IksZgtDmFc5rRwl8lWQ+8F/hd4HDggxPpNMnhwOnAOcOaLwDWJDmbzuT1mRPpQ5I0dqM+p1BVNwBLk7yczr/kV1fVpyfaaVX9HJi7W9sOOncjSZL6ZLQ5hTclub55VuEI4EXA7CRXJDm1ZxVKknpm1DmFqnoGncnld1bVQ1X1P+jcRnpGT6qTJPXUaJePfpjkg3SeZr51qLF59cQfT3VhkqTeGy0UlgIvBB4E1vamHElSP40WCk+sqr/b08YkAY6uqs2TX5YkqR9GC4X/nuQgOs8LXAtsB2YCvwk8l86dQucBhoIkHSBGe07hzCRPB14DvAFYQOeNprcAXwHOr6pdPalSktQTe3tO4WbgPT2qRZLUZ355TZLUMhQkSS1DQZLU2msoJLk4yUubO5EkSQewbv5D/wng1cDGJBckOW6Ka5Ik9cleQ6Gqrqyq19D5uM6dwNok/5jkrCQzprpASVLvdHVJKMlc4PXAHwDXAx+jExK+/kKSDiCjPqcAkOQS4Djg08DLq2pLs+nzzcd3JEkHiL2GAvDxqvr6SBuqanCS65Ek9VE3l4+elmTW0EqS2UneMnUlSZL6pZtQeGNV/WRopfmewhsn0mmSWUm+mOTWJLck+XdJ5iRZm2Rjs5w9kT4kSWPXTSgc1LwmG4AkBwOHTrDfjwFfrarjgBPovGRvJbCuqhYD65p1SVIPdRMKVwBrkixJ8jzgIuCr4+0wyeOA04BPAlTVL5uRyFJgdbPbamDZePuQJI1PNxPN7wLOAd4MBPga8NcT6POpdL7N8KkkJ9D5VsO5wPyhO5uqakuSeSMdnGQFsAJg0aJFEyhDkrS7VFVvO0wGge8Cz6qqa5J8DPhX4G1VNWvYfjuratR5hcHBwVq/3rtiJWkskly7p7tHu3n30eJmUvjmJHcM/ZlAPZuBzVV1TbP+RToPwm1NsqDpcwGwbQJ9SJLGoZs5hU/Ref/RQ3Q+w3khnQfZxqWqfgTcneTYpmkJcDNwObC8aVtO5zOgkqQe6mZO4bCqWpckVXUX8L4k36Lzfebxehvw2SSHAncAZ9EJqDVJzgY2AWdO4PySpHHoJhR2Na/N3pjkD4EfAiNOAnerqjYAI13PWjKR80qSJqaby0fvAA4H3g48E3gtv7rMI0k6gIw6UmgeVHtlVb0TuI/OZR5J0gFq1JFCVT0MPHP4E82SpANXN3MK1wOXJfkCcP9QY1VdMmVVSZL6optQmAPsAJ43rK0AQ0GSDjB7DYWqch5BkqaJbr689ik6I4NfU1VvmJKKJEl9083loy8N+z0TOAO4Z2rKkST1UzeXjy4evp7kIuDKKatIktQ33Ty8trvFgO+slqQDUDdzCj/j1+cUfkTnGwuSpANMN5ePjuxFIZKk/uvmewpnJHn8sPVZSZZNaVWSpL7oZk7hvKr66dBK8z3libw2W5K0j+omFEbap5tbWSVJ+5luQmF9kg8n+Y0kT03yEeDaqS5MktR73YTC24BfAp8H1gAPAG+dyqIkSf3Rzd1H9wMre1CLJKnPurn7aG2SWcPWZye5YiKdJrkzyQ+SbEiyvmmb0/S1sVnOnkgfkqSx6+by0VHNHUcAVNVOJviN5sZzq+rEqhr6VvNKYF1VLQbW4ehEknqum1B4JEn7WoskT2aEt6ZOgqXA6ub3amDZFPQhSRpFN7eWvgf4dpKrm/XTgBUT7LeAryUp4K+qahUwv6q2AFTVliQjjkaSrBjqf9EiX8EkSZOpm4nmryY5CTgFCPBHVfXjCfb7rKq6p/kP/9okt3Z7YBMgqwAGBwenYsQiSdNWt29JfRjYBvwUeHqS0ybSaVXd0yy3AZcCJwNbkywAaJbbJtKHJGnsurn76A+AbwJXAO9vlu8bb4dJjkhy5NBv4AXAjcDlwPJmt+XAZePtQ5I0Pt2MFM4Ffge4q6qeCzwD2D6BPufTmaO4Afge8OWq+ipwAXB6ko3A6c26JKmHuplo3lVVu5KQ5DFVdWuSY8fbYVXdAZwwQvsOYMl4zytJmrhuQmFz8/Da39KZFN6J32iWpANSN3cfndH8fF+SbwCPB746pVVJkvpiTK/Arqqr976XJGl/1e0tqZKkacBQkCS1DAVJUstQkCS1DAVJUstQkCS1DAVJUstQkCS1DAVJUstQkCS1DAVJUstQkCS1DAVJUstQkCS1DAVJUqtvoZDk4CTXJ/lSsz4nydokG5vl7H7VJknTVT9HCucCtwxbXwmsq6rFwLpmXZLUQ30JhSQLgZcCfz2seSmwuvm9GljW47Ikadrr10jho8CfAo8Ma5tfVVsAmuW8kQ5MsiLJ+iTrt2/fPuWFStJ00vNQSPIyYFtVXTue46tqVVUNVtXgwMDAJFcnSdPbIX3o81nA7yV5CTATeFySzwBbkyyoqi1JFgDb+lCbJE1rPR8pVNW7q2phVR0DvAr4elW9FrgcWN7sthy4rNe1SdJ0ty89p3ABcHqSjcDpzbokqYf6cfmoVVVXAVc1v3cAS/pZjyRNd/vSSEGS1GeGgiSpZShIklqGgiSpZShIklqGgiSpZShIklqGgiSpZShIklqGgiSpZShIklqGgiSpZShIklp9fUtqvx2z8sv9LkGSxuXOC146Jed1pCBJahkKkqSWoSBJahkKkqRWz0Mhycwk30tyQ5Kbkry/aZ+TZG2Sjc1ydq9rk6Tprh8jhV8Az6uqE4ATgRclOQVYCayrqsXAumZdktRDPQ+F6rivWZ3R/ClgKbC6aV8NLOt1bZI03fVlTiHJwUk2ANuAtVV1DTC/qrYANMt5/ahNkqazvoRCVT1cVScCC4GTkxzf7bFJViRZn2T99u3bp6xGSZqO+nr3UVX9BLgKeBGwNckCgGa5bQ/HrKqqwaoaHBgY6FWpkjQt9OPuo4Eks5rfhwHPB24FLgeWN7stBy7rdW2SNN31491HC4DVSQ6mE0prqupLSb4DrElyNrAJOLMPtUnStNbzUKiq7wPPGKF9B7Ck1/VIkn7FJ5olSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSa2eh0KSJyX5RpJbktyU5NymfU6StUk2NsvZva5Nkqa7fowUHgL+pKqeBpwCvDXJ04GVwLqqWgysa9YlST3U81Coqi1VdV3z+2fALcDRwFJgdbPbamBZr2uTpOkuVdW/zpNjgG8CxwObqmrWsG07q+pRl5CSrABWNKvHArdNfaXSuBwF/LjfRUgjeHJVDYy0oW+hkOSxwNXA+VV1SZKfdBMK0v4iyfqqGux3HdJY9OXuoyQzgIuBz1bVJU3z1iQLmu0LgG39qE2SprN+3H0U4JPALVX14WGbLgeWN7+XA5f1ujZJmu56fvkoybOBbwE/AB5pmv8MuAZYAywCNgFnVtW9PS1OmkRJVlTVqn7XIY1FXyeaJUn7Fp9oliS1DAVJUstQkLqQ5OEkG5pXs9yQ5I+THJTkhU37hiT3Jbmt+X1hkrnNK13uS/Lx3c53aJJVSf4pya1JXtGvv5s03CH9LkDaTzxQVScCJJkHfA54fFWdB1zRtF8F/KeqWt+sHwG8l87Dmcfvdr73ANuq6reSHATM6cVfQtobRwrSGFXVNjpP1f9hc4v1nva7v6q+DewaYfMbgP/S7PdIVfnks/YJhoI0DlV1B53//8wb67FJZjU/P5jkuiRfSDJ/MuuTxstQkMZvj6OEvTgEWAj8Q1WdBHwH+NCkVSVNgKEgjUOSpwIPM77XsewAfg5c2qx/AThpkkqTJsRQkMYoyQDwl8DHaxxPfzbH/B3wnKZpCXDzpBUoTYB3H0ndOSzJBmAGnQ9FfRr48KhHAEnuBB4HHJpkGfCCqroZeBfw6SQfBbYDZ01J1dIY+ZoLSVLLy0eSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpNb/ByRDVjqN0Hp3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_names = ['DT16']\n",
    "accuracy = [dt16_accuracy]\n",
    "\n",
    "#model_names = ['Mobilenet', 'Inception', 'Resnet', 'LR', 'KNN', 'DT16', 'NB']\n",
    "# accuracy = [mobilenet_right/len(img_nums), inception_right/len(img_nums),\n",
    "#             resnet_right/len(img_nums), log_reg_accuracy, knn_accuracy, dt16_accuracy, nb_accuracy]\n",
    "\n",
    "for i in range(len(accuracy)):\n",
    "    accuracy[i] = accuracy[i]*100\n",
    "\n",
    "ypos = np.arange(len(model_names))\n",
    "\n",
    "plt.xticks(ypos, model_names)\n",
    "plt.ylabel(\"accuracy (%)\")\n",
    "plt.title(\"{} accuracy\".format(\"Top-1\"))\n",
    "plt.bar(ypos, accuracy)\n",
    "plt.ylim(top = 100)\n",
    "plt.ylim(bottom = 20)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c250d03908>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "times = [dt16_time]\n",
    "times_premodel = [dt16_premodel_overhead]\n",
    "\n",
    "# times = [mobilenet_time/len(img_nums), inception_time/len(img_nums),\n",
    "#          resnet_time/len(img_nums), log_reg_time, knn_time, dt16_time, nb_time]\n",
    "# times_premodel = [0, 0, 0, log_reg_premodel_overhead, knn_premodel_overhead, dt16_premodel_overhead, nb_premodel_overhead]\n",
    "\n",
    "for i in range(len(times)):\n",
    "    times[i] = times[i]/1000\n",
    "\n",
    "for i in range(len(times_premodel)):\n",
    "    times_premodel[i] = times_premodel[i]/1000\n",
    "    \n",
    "plt.xticks(ypos, model_names)\n",
    "plt.ylabel(\"inference time (s)\")\n",
    "plt.title(\"Inference time\")\n",
    "plt.bar(ypos, times, label = \"Inference\")\n",
    "plt.bar(ypos, times_premodel, label = \"Premodel\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esrg",
   "language": "python",
   "name": "esrg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
