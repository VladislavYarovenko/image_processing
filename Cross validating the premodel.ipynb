{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">**Cross validating the premodel**</font>\n",
    "<br /><br />\n",
    "<font size=\"3\">All the timings and accuracy values are taken from the <font color = \"green\">database</font>. The average premodel feature extraction and prediction time were calculated <font color = \"green\">separately</font> and added to premodel inference time.</font>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">First, we import the necessary libraries and start the *image generator* class.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, neighbors\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import premodel\n",
    "#!pip install --user imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import image_generator\n",
    "import database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/val/images\\ILSVRC2012_val_00005461.JPEG butcher shop, meat market\n",
      "images/val/images\\ILSVRC2012_val_00002882.JPEG Newfoundland, Newfoundland dog\n",
      "images/val/images\\ILSVRC2012_val_00007356.JPEG Lakeland terrier\n",
      "images/val/images\\ILSVRC2012_val_00001864.JPEG cradle\n",
      "images/val/images\\ILSVRC2012_val_00004263.JPEG toilet seat\n",
      "images/val/images\\ILSVRC2012_val_00014990.JPEG cinema, movie theater, movie theatre, movie house, picture palace\n",
      "images/val/images\\ILSVRC2012_val_00009890.JPEG rock python, rock snake, Python sebae\n",
      "images/val/images\\ILSVRC2012_val_00020849.JPEG scuba diver\n",
      "images/val/images\\ILSVRC2012_val_00043647.JPEG geyser\n",
      "images/val/images\\ILSVRC2012_val_00039710.JPEG lifeboat\n"
     ]
    }
   ],
   "source": [
    "image_generator.main()\n",
    "imgGen = image_generator.ImageGenerator('images/val/images', 'images/val/val.txt', 'images/val/synset_words.txt')\n",
    "label_list = imgGen.get_label_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">**Running the premodel**</font>\n",
    "<br /><br />\n",
    "<font size=\"3\">We cross validate two premodels (<font color = \"green\">logistic regression</font> and <font color = \"green\">knn</font>) with <font color = \"green\">10-fold cross validation</font> on <font color = \"green\">20k</font> images. So, we obtain the <u>predicted models</u> for all <font color = \"green\">20k</font> images.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "preference = 'Student'                # here, we select our csv file, Author or Student\n",
    "n = 1                          # 1 for top-1, 5 for top-5\n",
    "pre_model = premodel.Premodel(preference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_log_reg = pre_model.prototype(4999, ([('log_reg', 'log_reg', 'log_reg')]))  # logistic regression premodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_knn = pre_model.prototype(4999, ([('nn', 'nn', 'nn')]))      # knn premodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_dt16 = pre_model.prototype(4999, ([('dt16', 'dt16', 'dt16')]))      # dt16 premodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_nb = pre_model.prototype(4999, ([('nb', 'nb', 'nb')]))      # nb premodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">**Testing the accuracy of the premodel**</font>\n",
    "<br /><br />\n",
    "<font size=\"3\">First, we extract the predicted models for the 20k images for both <font color = \"green\">logistic regression</font> and <font color = \"green\">knn</font> premodels.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_num_from_name(img_name):          # obtaining the image number from image name\n",
    "    ext = []\n",
    "    for i in range(len(img_name)):\n",
    "        if i > 14 and i < 23:\n",
    "            ext.append(img_name[i])\n",
    "    j = 0\n",
    "    for i in range(len(ext)):\n",
    "        if ext[i] == '0':\n",
    "            j = j + 1\n",
    "        if ext[i] != '0':\n",
    "            break\n",
    "    rightNum = []\n",
    "    for i in range(j, len(ext)):\n",
    "        rightNum.append(ext[i])\n",
    "    rightNum = ''.join(rightNum)\n",
    "    rightNum = int(rightNum)\n",
    "    return rightNum\n",
    "\n",
    "\n",
    "predicted_models_log_reg = []                              # models predicted by logistic regression premodel\n",
    "for i in range(10):\n",
    "    for j in range(len(output_log_reg[5][i][1][0])):\n",
    "        img_paths = (output_log_reg[5][i][1][0][j][0])\n",
    "        img_nums = (img_num_from_name(img_paths))\n",
    "        if output_log_reg[5][i][1][0][j][4] == 'tf-mobilenet_v1' and output_log_reg[5][i][1][0][j][3] == 1:\n",
    "            predicted_models_log_reg.append([img_nums, 'mobilenet_v1'])\n",
    "        elif output_log_reg[5][i][1][0][j][4] == 'tf-inception_v4' and output_log_reg[5][i][1][0][j][3] == 2:\n",
    "            predicted_models_log_reg.append([img_nums, 'inception_v4'])\n",
    "        elif output_log_reg[5][i][1][0][j][4] == 'tf-resnet_v1_152' and output_log_reg[5][i][1][0][j][3] == 3:\n",
    "            predicted_models_log_reg.append([img_nums, 'resnet_v1_152'])\n",
    "        elif output_log_reg[5][i][1][0][j][4] == 'failed':\n",
    "            predicted_models_log_reg.append([img_nums, 'failed'])\n",
    "        \n",
    "\n",
    "predicted_models_knn = []                                    # models predicted by knn premodel            \n",
    "for i in range(10):\n",
    "    for j in range(len(output_knn[5][i][1][0])):\n",
    "        img_paths = (output_knn[5][i][1][0][j][0])\n",
    "        img_nums = (img_num_from_name(img_paths))\n",
    "        if output_knn[5][i][1][0][j][4] == 'tf-mobilenet_v1' and output_knn[5][i][1][0][j][3] == 1:\n",
    "            predicted_models_knn.append([img_nums, 'mobilenet_v1'])\n",
    "        elif output_knn[5][i][1][0][j][4] == 'tf-inception_v4' and output_knn[5][i][1][0][j][3] == 2:\n",
    "            predicted_models_knn.append([img_nums, 'inception_v4'])\n",
    "        elif output_knn[5][i][1][0][j][4] == 'tf-resnet_v1_152' and output_knn[5][i][1][0][j][3] == 3:\n",
    "            predicted_models_knn.append([img_nums, 'resnet_v1_152'])\n",
    "        elif output_knn[5][i][1][0][j][4] == 'failed':\n",
    "            predicted_models_knn.append([img_nums, 'failed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_models_dt16 = []                                    # models predicted by dt16 premodel            \n",
    "for i in range(10):\n",
    "    for j in range(len(output_dt16[5][i][1][0])):\n",
    "        img_paths = (output_dt16[5][i][1][0][j][0])\n",
    "        img_nums = (img_num_from_name(img_paths))\n",
    "        if output_dt16[5][i][1][0][j][4] == 'tf-mobilenet_v1' and output_dt16[5][i][1][0][j][3] == 1:\n",
    "            predicted_models_dt16.append([img_nums, 'mobilenet_v1'])\n",
    "        elif output_dt16[5][i][1][0][j][4] == 'tf-inception_v4' and output_dt16[5][i][1][0][j][3] == 2:\n",
    "            predicted_models_dt16.append([img_nums, 'inception_v4'])\n",
    "        elif output_dt16[5][i][1][0][j][4] == 'tf-resnet_v1_152' and output_dt16[5][i][1][0][j][3] == 3:\n",
    "            predicted_models_dt16.append([img_nums, 'resnet_v1_152'])\n",
    "        elif output_dt16[5][i][1][0][j][4] == 'failed':\n",
    "            predicted_models_dt16.append([img_nums, 'failed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_models_nb = []                                    # models predicted by nb premodel            \n",
    "for i in range(10):\n",
    "    for j in range(len(output_nb[5][i][1][0])):\n",
    "        img_paths = (output_nb[5][i][1][0][j][0])\n",
    "        img_nums = (img_num_from_name(img_paths))\n",
    "        if output_nb[5][i][1][0][j][4] == 'tf-mobilenet_v1' and output_nb[5][i][1][0][j][3] == 1:\n",
    "            predicted_models_nb.append([img_nums, 'mobilenet_v1'])\n",
    "        elif output_nb[5][i][1][0][j][4] == 'tf-inception_v4' and output_nb[5][i][1][0][j][3] == 2:\n",
    "            predicted_models_nb.append([img_nums, 'inception_v4'])\n",
    "        elif output_nb[5][i][1][0][j][4] == 'tf-resnet_v1_152' and output_nb[5][i][1][0][j][3] == 3:\n",
    "            predicted_models_nb.append([img_nums, 'resnet_v1_152'])\n",
    "        elif output_nb[5][i][1][0][j][4] == 'failed':\n",
    "            predicted_models_nb.append([img_nums, 'failed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4999\n"
     ]
    }
   ],
   "source": [
    "print(len(predicted_models_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4999\n"
     ]
    }
   ],
   "source": [
    "print(len(predicted_models_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4999\n"
     ]
    }
   ],
   "source": [
    "print(len(predicted_models_dt16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4999\n"
     ]
    }
   ],
   "source": [
    "print(len(predicted_models_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">Now, we obtain the <font color = \"green\">accuracy</font> and <font color = \"green\">inference time</font> results of the predicted models from the database.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression premodel accuracy = 0.7677535507101421\n",
      "Logistic regression premodel average inference time = 541.9984492307692\n"
     ]
    }
   ],
   "source": [
    "accuracy_premodel = 0\n",
    "time_premodel = 0\n",
    "times = 0\n",
    "log_reg_premodel_overhead = 42.39268                                      # average logistic regression premodel overhead\n",
    "\n",
    "for i in range(len(predicted_models_log_reg)):\n",
    "    if predicted_models_log_reg[i][1] != 'failed':\n",
    "        times = times + 1                          # get_model_top_n (next line), where n is 1 or 5\n",
    "        accuracy_premodel = accuracy_premodel + (database.get_model_top_n(\"inference\", predicted_models_log_reg[i][0], predicted_models_log_reg[i][1], n))\n",
    "        time_premodel = time_premodel + (database.get_model_time(\"inference\", predicted_models_log_reg[i][0], predicted_models_log_reg[i][1]))\n",
    "\n",
    "log_reg_accuracy = accuracy_premodel/len(predicted_models_log_reg)               # logistic regression premodel accuracy\n",
    "log_reg_time = (time_premodel/times) + log_reg_premodel_overhead                 # logistic regression premodel inference time       \n",
    "print(\"Logistic regression premodel accuracy = {}\".format(log_reg_accuracy))\n",
    "print(\"Logistic regression premodel average inference time = {}\".format(log_reg_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_premodel = 0\n",
    "# time_premodel = 0\n",
    "# times = 0\n",
    "# knn_premodel_overhead = 43.00882                                           # average knn premodel overhead\n",
    "\n",
    "# for i in range(len(predicted_models_knn)):\n",
    "#     if predicted_models_knn[i][1] != 'failed':\n",
    "#         times = times + 1                           # get_model_top_n (next line), where n is 1 or 5\n",
    "#         accuracy_premodel = accuracy_premodel + (database.get_model_top_n(\"inference\", predicted_models_knn[i][0], predicted_models_knn[i][1], n))\n",
    "#         time_premodel = time_premodel + (database.get_model_time(\"inference\", predicted_models_knn[i][0], predicted_models_knn[i][1]))\n",
    "\n",
    "# knn_accuracy = accuracy_premodel/len(predicted_models_knn)                        # knn premodel accuracy\n",
    "# knn_time = (time_premodel/times) + knn_premodel_overhead                             # knnn premodel inference time\n",
    "# print(\"KNN premodel accuracy = {}\".format(knn_accuracy))\n",
    "# print(\"KNN premodel average inference time = {}\".format(knn_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT16 premodel accuracy = 0.7563512702540508\n",
      "DT16 premodel average inference time = 563.9774116919959\n"
     ]
    }
   ],
   "source": [
    "accuracy_premodel = 0\n",
    "time_premodel = 0\n",
    "times = 0\n",
    "dt16_premodel_overhead = 43.00882                                           # average dt16 premodel overhead\n",
    "\n",
    "for i in range(len(predicted_models_dt16)):\n",
    "    if predicted_models_dt16[i][1] != 'failed':\n",
    "        times = times + 1                           # get_model_top_n (next line), where n is 1 or 5\n",
    "        accuracy_premodel = accuracy_premodel + (database.get_model_top_n(\"inference\", predicted_models_dt16[i][0], predicted_models_dt16[i][1], n))\n",
    "        time_premodel = time_premodel + (database.get_model_time(\"inference\", predicted_models_dt16[i][0], predicted_models_dt16[i][1]))\n",
    "\n",
    "dt16_accuracy = accuracy_premodel/len(predicted_models_dt16)                        # dt16 premodel accuracy\n",
    "dt16_time = (time_premodel/times) + dt16_premodel_overhead                             # dt16 premodel inference time\n",
    "print(\"DT16 premodel accuracy = {}\".format(dt16_accuracy))\n",
    "print(\"DT16 premodel average inference time = {}\".format(dt16_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">**Comparing the results to MobileNet, Inception and ResNet**</font>\n",
    "<br /><br />\n",
    "<font size=\"3\">We start by getting the <font color = \"green\">image numbers</font> of the 20k images.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_premodel = 0\n",
    "# time_premodel = 0\n",
    "# times = 0\n",
    "# nb_premodel_overhead = 43.00882                                           # average nb premodel overhead\n",
    "\n",
    "# for i in range(len(predicted_models_nb)):\n",
    "#     if predicted_models_nb[i][1] != 'failed':\n",
    "#         times = times + 1                           # get_model_top_n (next line), where n is 1 or 5\n",
    "#         accuracy_premodel = accuracy_premodel + (database.get_model_top_n(\"inference\", predicted_models_nb[i][0], predicted_models_nb[i][1], n))\n",
    "#         time_premodel = time_premodel + (database.get_model_time(\"inference\", predicted_models_nb[i][0], predicted_models_nb[i][1]))\n",
    "\n",
    "# nb_accuracy = accuracy_premodel/len(predicted_models_nb)                        # nb premodel accuracy\n",
    "# nb_time = (time_premodel/times) + nb_premodel_overhead                             # nb premodel inference time\n",
    "# print(\"NB premodel accuracy = {}\".format(nb_accuracy))\n",
    "# print(\"NB premodel average inference time = {}\".format(nb_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_nums = []\n",
    "for i in range(1, 4999):                        # the same range of images is selected\n",
    "    img_nums.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">Finally, we obtain the <font color = \"green\">accuracy</font> and <font color = \"green\">inference time</font> results for each DNN separately from the database.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mobilenet top-1 accuracy = 0.720688275310124\n",
      "Mobilenet average inference time = 155.14645858343337\n",
      "Inception top-1 accuracy = 0.7985194077631053\n",
      "Inception average inference time = 727.6622649059624\n",
      "ResNet top-1 accuracy = 0.7743097238895558\n",
      "ResNet average inference time = 968.4637855142057\n"
     ]
    }
   ],
   "source": [
    "mobilenet_right = 0\n",
    "mobilenet_time = 0\n",
    "for i in range(len(img_nums)):                            # obtaining accuracy and inference time for each image\n",
    "    mobilenet_right = mobilenet_right + (database.get_model_top_n(\"inference\", img_nums[i], 'mobilenet_v1', n))\n",
    "    mobilenet_time = mobilenet_time + (database.get_model_time(\"inference\", img_nums[i], 'mobilenet_v1'))\n",
    "print(\"Mobilenet top-{} accuracy = {}\".format(n, mobilenet_right/len(img_nums)))          # accuracy over 20k images\n",
    "print(\"Mobilenet average inference time = {}\".format(mobilenet_time/len(img_nums)))   # average inference time over 20k images\n",
    "\n",
    "inception_right = 0\n",
    "inception_time = 0\n",
    "for i in range(len(img_nums)):\n",
    "    inception_right = inception_right + (database.get_model_top_n(\"inference\", img_nums[i], 'inception_v4', n))\n",
    "    inception_time = inception_time + (database.get_model_time(\"inference\", img_nums[i], 'inception_v4'))\n",
    "print(\"Inception top-{} accuracy = {}\".format(n, inception_right/len(img_nums)))\n",
    "print(\"Inception average inference time = {}\".format(inception_time/len(img_nums)))\n",
    "\n",
    "resnet_right = 0\n",
    "resnet_time = 0\n",
    "for i in range(len(img_nums)):\n",
    "    resnet_right = resnet_right + (database.get_model_top_n(\"inference\", img_nums[i], 'resnet_v1_152', n))\n",
    "    resnet_time = resnet_time + (database.get_model_time(\"inference\", img_nums[i], 'resnet_v1_152'))\n",
    "print(\"ResNet top-{} accuracy = {}\".format(n, resnet_right/len(img_nums)))\n",
    "print(\"ResNet average inference time = {}\".format(resnet_time/len(img_nums)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">Here, we plot the results for comparison.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x27461034710>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_names = ['Mobilenet', 'Inception', 'Resnet', 'LR', 'DT16']\n",
    "# accuracy = [mobilenet_right/len(img_nums), inception_right/len(img_nums),\n",
    "#             resnet_right/len(img_nums), log_reg_accuracy, dt16_accuracy]\n",
    "\n",
    "model_names = ['LR', 'DT16']\n",
    "accuracy = [log_reg_accuracy, dt16_accuracy]\n",
    "\n",
    "#model_names = ['Mobilenet', 'Inception', 'Resnet', 'LR', 'KNN', 'DT16', 'NB']\n",
    "# accuracy = [mobilenet_right/len(img_nums), inception_right/len(img_nums),\n",
    "#             resnet_right/len(img_nums), log_reg_accuracy, knn_accuracy, dt16_accuracy, nb_accuracy]\n",
    "\n",
    "for i in range(len(accuracy)):\n",
    "    accuracy[i] = accuracy[i]*100\n",
    "\n",
    "ypos = np.arange(len(model_names))\n",
    "\n",
    "plt.xticks(ypos, model_names)\n",
    "plt.ylabel(\"accuracy (%)\")\n",
    "plt.title(\"{} accuracy\".format(\"Top-1\"))\n",
    "plt.bar(ypos, accuracy)\n",
    "plt.ylim(top = 85)\n",
    "plt.ylim(bottom = 20)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-a09f4e3c8004>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Inference time\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mypos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Inference\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mypos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimes_premodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Premodel\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\esrg\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[0;32m   2487\u001b[0m     return gca().bar(\n\u001b[0;32m   2488\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbottom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malign\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2489\u001b[1;33m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\esrg\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1446\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1447\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\esrg\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[0;32m   2430\u001b[0m         x, height, width, y, linewidth = np.broadcast_arrays(\n\u001b[0;32m   2431\u001b[0m             \u001b[1;31m# Make args iterable too.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2432\u001b[1;33m             np.atleast_1d(x), height, width, y, linewidth)\n\u001b[0m\u001b[0;32m   2433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2434\u001b[0m         \u001b[1;31m# Now that units have been converted, set the tick locations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\esrg\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[1;34m(subok, *args)\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\esrg\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;31m# consistently\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m     \u001b[1;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# times = [mobilenet_time/len(img_nums), inception_time/len(img_nums),\n",
    "#          resnet_time/len(img_nums), log_reg_time, dt16_time]\n",
    "# times_premodel = [0, 0, 0,  log_reg_premodel_overhead, dt16_premodel_overhead]\n",
    "\n",
    "times = [log_reg_time, dt16_time]\n",
    "times_premodel = [0, 0, 0,  log_reg_premodel_overhead, dt16_premodel_overhead]\n",
    "\n",
    "# times = [mobilenet_time/len(img_nums), inception_time/len(img_nums),\n",
    "#          resnet_time/len(img_nums), log_reg_time, knn_time, dt16_time, nb_time]\n",
    "# times_premodel = [0, 0, 0, log_reg_premodel_overhead, knn_premodel_overhead, dt16_premodel_overhead, nb_premodel_overhead]\n",
    "\n",
    "for i in range(len(times)):\n",
    "    times[i] = times[i]/1000\n",
    "\n",
    "for i in range(len(times_premodel)):\n",
    "    times_premodel[i] = times_premodel[i]/1000\n",
    "    \n",
    "plt.xticks(ypos, model_names)\n",
    "plt.ylabel(\"inference time (s)\")\n",
    "plt.title(\"Inference time\")\n",
    "plt.bar(ypos, times, label = \"Inference\")\n",
    "plt.bar(ypos, times_premodel, label = \"Premodel\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['MobileNet', 'Inception', 'Resnet', 'Log-Reg', 'KNN', 'DT16', 'NB']\n",
    "rows = ['Top-1 accuracy, %', 'Avg inference time, s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esrg",
   "language": "python",
   "name": "esrg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
